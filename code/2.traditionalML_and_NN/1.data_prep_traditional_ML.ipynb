{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a85aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('../../data/train_long_data.pkl')\n",
    "val_long_data = pd.read_pickle('../../data/val_long_data.pkl')\n",
    "test_long_data = pd.read_pickle('../../data/test_long_data.pkl')\n",
    "outcomes = pd.read_pickle('../../data/SSI_outcomes.pkl')\n",
    "with open('../../data/feature_selection_50_columns.pkl', 'rb') as f:\n",
    "    keep_columns = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08724c41",
   "metadata": {},
   "source": [
    "# Train Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad874d",
   "metadata": {},
   "source": [
    "### Aggregate data for each patient and feature\n",
    "Categorical features (like meds, micro results, encounters, dx and px codes) do a count; impute with 0\n",
    "\n",
    "Numerical features (labs and vitals, terminology = LOINC) get mean, median, min, max; impute with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a3bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = train_data.loc[train_data['TERMINOLOGY'] == 'LOINC'].copy()\n",
    "\n",
    "median = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).median().reset_index()\n",
    "median['FEATURE'] = median['FEATURE'] + '_MEDIAN'\n",
    "median = median.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "mean = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).mean().reset_index()\n",
    "mean['FEATURE'] = mean['FEATURE'] + '_MEAN'\n",
    "mean = mean.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "minimum = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).min().reset_index()\n",
    "minimum['FEATURE'] = minimum['FEATURE'] + '_MIN'\n",
    "minimum = minimum.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "maximum = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).max().reset_index()\n",
    "maximum['FEATURE'] = maximum['FEATURE'] + '_MAX'\n",
    "maximum = maximum.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "train_medians = pd.concat([median.median(numeric_only=True), \n",
    "                           mean.median(numeric_only=True), \n",
    "                           minimum.median(numeric_only=True), \n",
    "                           maximum.median(numeric_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ebc18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = train_data.loc[train_data['TERMINOLOGY'] != 'LOINC'].copy()\n",
    "\n",
    "count = categorical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).sum().reset_index()\n",
    "count = count.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b921a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_train = train_data[['PT_KEY']].drop_duplicates().merge(count, how='left', on='PT_KEY')\n",
    "agg_train = agg_train.merge(median, how='left', on='PT_KEY')\n",
    "agg_train = agg_train.merge(mean, how='left', on='PT_KEY')\n",
    "agg_train = agg_train.merge(minimum, how='left', on='PT_KEY')\n",
    "agg_train = agg_train.merge(maximum, how='left', on='PT_KEY')\n",
    "\n",
    "agg_train = agg_train.fillna(train_medians.to_dict())\n",
    "agg_train = agg_train.fillna(0)\n",
    "\n",
    "agg_train = agg_train.merge(outcomes, how='inner', on='PT_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e844344f",
   "metadata": {},
   "source": [
    "### Keep selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772db06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=agg_train[keep_columns].copy()\n",
    "y_train=agg_train['SSI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a2004",
   "metadata": {},
   "source": [
    "### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train), \n",
    "                              columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843bb9d8",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled.to_pickle('../../data/train_X_agg.pkl')\n",
    "# y_train.to_pickle('../../data/train_y_agg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a451089b",
   "metadata": {},
   "source": [
    "# Validation Set\n",
    "### Aggregate data for each patient and feature\n",
    "Categorical features (like meds, micro results, encounters, dx and px codes) do a count; impute with 0\n",
    "\n",
    "Numerical features (labs and vitals, terminology = LOINC) get mean, median, min, max; impute with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a50d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = val_long_data.loc[val_long_data['TERMINOLOGY'] == 'LOINC'].copy()\n",
    "\n",
    "median = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).median().reset_index()\n",
    "median['FEATURE'] = median['FEATURE'] + '_MEDIAN'\n",
    "median = median.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "mean = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).mean().reset_index()\n",
    "mean['FEATURE'] = mean['FEATURE'] + '_MEAN'\n",
    "mean = mean.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "minimum = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).min().reset_index()\n",
    "minimum['FEATURE'] = minimum['FEATURE'] + '_MIN'\n",
    "minimum = minimum.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "maximum = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).max().reset_index()\n",
    "maximum['FEATURE'] = maximum['FEATURE'] + '_MAX'\n",
    "maximum = maximum.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = val_long_data.loc[val_long_data['TERMINOLOGY'] != 'LOINC'].copy()\n",
    "\n",
    "count = categorical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).sum().reset_index()\n",
    "count = count.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e32438",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_val = val_long_data[['PT_KEY']].drop_duplicates().merge(count, how='left', on='PT_KEY')\n",
    "agg_val = agg_val.merge(median, how='left', on='PT_KEY')\n",
    "agg_val = agg_val.merge(mean, how='left', on='PT_KEY')\n",
    "agg_val = agg_val.merge(minimum, how='left', on='PT_KEY')\n",
    "agg_val = agg_val.merge(maximum, how='left', on='PT_KEY')\n",
    "\n",
    "agg_val = agg_val.fillna(train_medians.to_dict())\n",
    "agg_val = agg_val.fillna(0)\n",
    "\n",
    "agg_val = agg_val.merge(outcomes, how='inner', on='PT_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a516d984",
   "metadata": {},
   "source": [
    "### Keep selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=agg_val[keep_columns].copy()\n",
    "y_val=agg_val['SSI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c20e28",
   "metadata": {},
   "source": [
    "### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a66a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = pd.DataFrame(scaler.transform(X_val),columns = X_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3540330",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760bbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val_scaled.to_pickle('../../data/val_X_agg.pkl')\n",
    "# y_val.to_pickle('../../data/val_y_agg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799463d",
   "metadata": {},
   "source": [
    "# Test Set\n",
    "### Aggregate data for each patient and feature\n",
    "Categorical features (like meds, micro results, encounters, dx and px codes) do a count; impute with 0\n",
    "\n",
    "Numerical features (labs and vitals, terminology = LOINC) get mean, median, min, max; impute with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4794448",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = test_long_data.loc[test_long_data['TERMINOLOGY'] == 'LOINC'].copy()\n",
    "\n",
    "median = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).median().reset_index()\n",
    "median['FEATURE'] = median['FEATURE'] + '_MEDIAN'\n",
    "median = median.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "mean = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).mean().reset_index()\n",
    "mean['FEATURE'] = mean['FEATURE'] + '_MEAN'\n",
    "mean = mean.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "minimum = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).min().reset_index()\n",
    "minimum['FEATURE'] = minimum['FEATURE'] + '_MIN'\n",
    "minimum = minimum.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "maximum = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).max().reset_index()\n",
    "maximum['FEATURE'] = maximum['FEATURE'] + '_MAX'\n",
    "maximum = maximum.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69954c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = test_long_data.loc[test_long_data['TERMINOLOGY'] != 'LOINC'].copy()\n",
    "\n",
    "count = categorical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).sum().reset_index()\n",
    "count = count.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0081c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_test = test_long_data[['PT_KEY']].drop_duplicates().merge(count, how='left', on='PT_KEY')\n",
    "agg_test = agg_test.merge(median, how='left', on='PT_KEY')\n",
    "agg_test = agg_test.merge(mean, how='left', on='PT_KEY')\n",
    "agg_test = agg_test.merge(minimum, how='left', on='PT_KEY')\n",
    "agg_test = agg_test.merge(maximum, how='left', on='PT_KEY')\n",
    "\n",
    "agg_test = agg_test.fillna(train_medians.to_dict())\n",
    "agg_test = agg_test.fillna(0)\n",
    "\n",
    "agg_test = agg_test.merge(outcomes, how='inner', on='PT_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34024f18",
   "metadata": {},
   "source": [
    "### Keep selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=agg_test[keep_columns].copy()\n",
    "y_test=agg_test['SSI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15fe596",
   "metadata": {},
   "source": [
    "### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test),columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65422c0f",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c571d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_scaled.to_pickle('../../data/test_X_agg.pkl')\n",
    "# y_test.to_pickle('../../data/test_y_agg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d511d692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
