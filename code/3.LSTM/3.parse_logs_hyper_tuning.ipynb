{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16914c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3292578",
   "metadata": {},
   "source": [
    "# Parse Log Files\n",
    "\n",
    "Get data from log files to identify best batch size and learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea18e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hyperparameter_log_file(log_number):\n",
    "    best_batch_size_ls = []\n",
    "    best_lr_ls = []\n",
    "    best_fold_ls = []\n",
    "    best_rep_ls = []\n",
    "    best_epoch_ls = []\n",
    "\n",
    "    batch_size_ls = []\n",
    "    lr_ls = []\n",
    "    fold_ls = []\n",
    "    rep_ls = []\n",
    "    epoch_ls = []\n",
    "    train_ap_ls = []\n",
    "    val_ap_ls = []\n",
    "    train_time_ls = []\n",
    "    val_time_ls = []\n",
    "\n",
    "    with open('logs/hyperparameter_tuning_%s.log' % log_number, 'r') as f:\n",
    "        for line in f:\n",
    "            if re.search('BATCH SIZE', line):\n",
    "                batch_size = int(re.search('BATCH SIZE: (\\d+)', line).group(1))\n",
    "\n",
    "            if re.search('LR', line):\n",
    "                lr = float(re.search('LR: (0.\\d+)', line).group(1))\n",
    "\n",
    "            if re.search('Rep', line):\n",
    "                m1 = re.search('Fold (\\d{1,2}); Rep (\\d)', line)\n",
    "                fold = int(m1.group(1))\n",
    "                rep = int(m1.group(2))\n",
    "\n",
    "            if re.search('EPOCH #(\\d{1,3}): TRAIN AP', line):\n",
    "                m2 = re.search('EPOCH #(\\d{1,4}): TRAIN AP (\\d.\\d+), VAL AP (\\d.\\d+), TRAIN TIME (\\d+)m (\\d+.\\d+)s, VAL TIME (\\d+)m (\\d+.\\d+)s', line)\n",
    "                batch_size_ls.append(batch_size)\n",
    "                lr_ls.append(lr)\n",
    "                fold_ls.append(fold)\n",
    "                rep_ls.append(rep)\n",
    "                epoch_ls.append(int(m2.group(1)))\n",
    "                train_ap_ls.append(float(m2.group(2)))\n",
    "                val_ap_ls.append(float(m2.group(3)))\n",
    "                train_time_ls.append(float(m2.group(4)) * 60 + float(m2.group(5)))\n",
    "                val_time_ls.append(float(m2.group(6)) * 60 + float(m2.group(7)))\n",
    "\n",
    "            if re.search('STOPPING', line):\n",
    "                m3 = re.search('EPOCH #(\\d{1,4})', line)\n",
    "                best_batch_size_ls.append(batch_size)\n",
    "                best_lr_ls.append(lr)\n",
    "                best_fold_ls.append(fold)\n",
    "                best_rep_ls.append(rep)\n",
    "                best_epoch_ls.append(int(m3.group(1)))\n",
    "\n",
    "\n",
    "    best_epoch = pd.DataFrame({'batch_size': best_batch_size_ls,\n",
    "                               'lr': best_lr_ls,\n",
    "                               'fold': best_fold_ls,\n",
    "                               'rep': best_rep_ls,\n",
    "                               'best_epoch': best_epoch_ls})\n",
    "\n",
    "    epoch_metrics = pd.DataFrame({'batch_size': batch_size_ls,\n",
    "                                  'lr': lr_ls,\n",
    "                                  'fold': fold_ls,\n",
    "                                  'rep': rep_ls,\n",
    "                                  'epoch': epoch_ls,\n",
    "                                  'train_ap': train_ap_ls,\n",
    "                                  'val_ap': val_ap_ls,\n",
    "                                  'train_time': train_time_ls,\n",
    "                                  'val_time': val_time_ls})\n",
    "    \n",
    "    best_epoch['best_epoch_flag'] = 1\n",
    "    epoch_metrics = epoch_metrics.merge(best_epoch, how='left', \n",
    "                                        left_on=['batch_size', 'lr', 'fold', 'rep', 'epoch'],\n",
    "                                        right_on=['batch_size', 'lr', 'fold', 'rep', 'best_epoch'])\n",
    "\n",
    "    epoch_metrics = epoch_metrics.drop(columns='best_epoch')\n",
    "    epoch_metrics['best_epoch_flag'] = epoch_metrics['best_epoch_flag'].fillna(0).astype('int')\n",
    "    epoch_metrics['total_time'] = epoch_metrics['train_time'] + epoch_metrics['val_time']\n",
    "\n",
    "    return epoch_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef1e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_metrics_1 = parse_hyperparameter_log_file(log_number='1') \n",
    "epoch_metrics_2 = parse_hyperparameter_log_file(log_number='2') \n",
    "epoch_metrics_3 = parse_hyperparameter_log_file(log_number='3') \n",
    "epoch_metrics_4 = parse_hyperparameter_log_file(log_number='4') \n",
    "epoch_metrics_5 = parse_hyperparameter_log_file(log_number='5') \n",
    "epoch_metrics_6 = parse_hyperparameter_log_file(log_number='6') \n",
    "epoch_metrics_7 = parse_hyperparameter_log_file(log_number='7') \n",
    "\n",
    "epoch_metrics = pd.concat([epoch_metrics_1, epoch_metrics_2, epoch_metrics_3, epoch_metrics_4, epoch_metrics_5, \n",
    "                           epoch_metrics_6, epoch_metrics_7]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_metrics.loc[epoch_metrics['best_epoch_flag'] == 1].sort_values('val_ap', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b2669",
   "metadata": {},
   "source": [
    "## Investigate to find the top hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d14d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_metrics(epoch_metrics):\n",
    "    batch_sizes = [128, 256, 512]\n",
    "    lrs = [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "\n",
    "    summary_metrics = pd.DataFrame()\n",
    "    for batch_size in batch_sizes: \n",
    "        for lr in lrs:\n",
    "            temp = epoch_metrics.loc[(epoch_metrics['best_epoch_flag'] == 1) &\n",
    "                                     (epoch_metrics['batch_size'] == batch_size) &\n",
    "                                     (epoch_metrics['lr'] == lr)]\n",
    "            val_ap_data = temp['val_ap'].values\n",
    "            ci = st.t.interval(alpha=0.95, df=len(val_ap_data)-1, loc=np.mean(val_ap_data), scale=st.sem(val_ap_data))\n",
    "\n",
    "            summary_metrics = pd.concat([summary_metrics, \n",
    "                                         pd.DataFrame({'batch_size': [batch_size],\n",
    "                                                       'lr': [lr],\n",
    "                                                       'mean_val_ap': [np.mean(val_ap_data)], \n",
    "                                                       'val_ap_low': [ci[0]], \n",
    "                                                       'val_ap_high': [ci[1]]})])\n",
    "    return summary_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8bba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_metrics = create_summary_metrics(epoch_metrics=epoch_metrics)\n",
    "summary_metrics.sort_values('mean_val_ap', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a672b",
   "metadata": {},
   "source": [
    "### Best hyperparameters: BATCH SIZE = 256; LEARNING RATE = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d989dd88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
