{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd462226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('../../data/train_long_data.pkl')\n",
    "outcomes = pd.read_pickle('../../data/SSI_outcomes.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d287989d",
   "metadata": {},
   "source": [
    "# Data Prep for Feature Selection\n",
    "\n",
    "Make a wide aggregated dataframe for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ede700",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = train_data.loc[train_data['TERMINOLOGY'] == 'LOINC'].copy()\n",
    "\n",
    "median = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).median().reset_index()\n",
    "median['FEATURE'] = median['FEATURE'] + '_MEDIAN'\n",
    "median = median.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "mean = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).mean().reset_index()\n",
    "mean['FEATURE'] = mean['FEATURE'] + '_MEAN'\n",
    "mean = mean.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "minimum = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).min().reset_index()\n",
    "minimum['FEATURE'] = minimum['FEATURE'] + '_MIN'\n",
    "minimum = minimum.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()\n",
    "\n",
    "maximum = numerical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).max().reset_index()\n",
    "maximum['FEATURE'] = maximum['FEATURE'] + '_MAX'\n",
    "maximum = maximum.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e70b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with medians\n",
    "train_medians = pd.concat([median.median(numeric_only=True), \n",
    "                           mean.median(numeric_only=True), \n",
    "                           minimum.median(numeric_only=True), \n",
    "                           maximum.median(numeric_only=True)])\n",
    "\n",
    "# train_medians.to_pickle('../../data/Time_Series_Dataset/wide_agg_medians.pkl') # These are only aggregated medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = train_data.loc[train_data['TERMINOLOGY'] != 'LOINC'].copy()\n",
    "\n",
    "count = categorical[['PT_KEY','FEATURE','VALUE']].groupby(['PT_KEY','FEATURE']).sum().reset_index()\n",
    "count = count.pivot_table(values='VALUE', index='PT_KEY', columns='FEATURE').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_train = train_data[['PT_KEY']].drop_duplicates().merge(count, how='left', on='PT_KEY')\n",
    "agg_train = agg_train.merge(median, how='left', on='PT_KEY')\n",
    "agg_train = agg_train.merge(mean, how='left', on='PT_KEY')\n",
    "agg_train = agg_train.merge(minimum, how='left', on='PT_KEY')\n",
    "agg_train = agg_train.merge(maximum, how='left', on='PT_KEY')\n",
    "\n",
    "agg_train = agg_train.fillna(train_medians.to_dict())\n",
    "agg_train = agg_train.fillna(0)\n",
    "\n",
    "agg_train = agg_train.merge(outcomes, how='inner', on='PT_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4879293b",
   "metadata": {},
   "source": [
    "### Scale Data\n",
    "Use MinMaxScaler (normalize values between 0 and 1) since data is not necessarily normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(agg_train.drop(columns=['PT_KEY','SSI']))\n",
    "scaled_agg_train = pd.DataFrame(scaler.transform(agg_train.drop(columns=['PT_KEY','SSI'])), \n",
    "                                columns = [col for col in agg_train.columns if col not in ['PT_KEY','SSI']])\n",
    "scaled_agg_train = pd.concat([agg_train[['PT_KEY','SSI']], scaled_agg_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_agg_train.to_pickle('../../data/train_wide_agg_scaled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31f784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
